---
title: "[**Pattern Discovery in Data Mining** *Programming Assignment: Frequent Itemset Mining Using Apriori*](https://www.coursera.org/learn/data-patterns)"
subtitle: "[**Data Mining** *by University of Illinois at Urbana-Champaign*](https://www.coursera.org/specializations/data-mining)"
author: "[®γσ, Eng Lian Hu](http://englianhu.wordpress.com) <img src='figure/ShirotoNorimichi2.jpg' width='24'> 白戸則道®"
date: "`r Sys.Date()`"
output:
  tufte::tufte_html:
    toc: yes
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
link-citations: yes
---

```{r, include = FALSE}
# bibliography: skeleton.bib
```

```{r libs, message = FALSE, warning = FALSE, cache = TRUE, include = FALSE}
## Setup Options, Loading Required Libraries and Preparing Environment
## Loading the packages and setting adjustment
suppressMessages(library('utils'))
suppressMessages(require('plyr', quietly = TRUE))
suppressMessages(require('BBmisc', quietly = TRUE))

pkgs <- c('jsonlite', 'arules', 'arulesViz', 'readr', 'knitr', 'stringr', 'stringi', 'dplyr', 'purrr', 'magrittr', 'formattable', 'DT', 'lubridate', 'googleVis', 'rvest')
suppressAll(l_ply(pkgs, require, quietly = TRUE, character.only = TRUE))
rm(pkgs)

## Set the googleVis options first to change the behaviour of plot.gvis, so that only the chart 
##  component of the HTML file is written into the output file.
op <- options(gvis.plot.tag = 'chart')
```

# Abstract

## Programming Assignment: Frequent Itemset Mining Using Apriori

You have not submitted. You must earn *70/100 points* to pass.
Deadline	*Pass this assignment by September 4, 11:59 PM PDT*

# 1. Instructions

  - Section [1.1 Input]
  - Section [1.2 Output]
  - Section [1.3 Important Tips]

**Description**

  In this programming assignment, you are required to implement the Apriori algorithm and apply it to mine frequent itemsets from a real-life data set.

## 1.1 Input

  The provided input file ("categories.txt") consists of the category lists of 77,185 places in the US. Each line corresponds to the category list of one place, where the list consists of a number of category instances (e.g., hotels, restaurants, etc.) that are separated by semicolons.

  An example line is provided below:

  Local Services; IT Services & Computer Repair

  In the example above, the corresponding place has two category instances: "Local Services" and "IT Services & Computer Repair".

[`categories.txt`](https://github.com/englianhu/Coursera-Data-Mining/blob/master/4%20Pattern%20Discovery%20in%20Data%20Mining/data/categories.txt)

```{r data, echo = FALSE, message = FALSE, warning = FALSE, results = 'asis'}
suppressMessages(require('arules', quietly = TRUE))
suppressMessages(require('BBmisc', quietly = TRUE))

lnk <- 'https://raw.githubusercontent.com/englianhu/Coursera-Data-Mining/master/4%20Pattern%20Discovery%20in%20Data%20Mining/data/categories.txt'

transDat <- suppressAll(read.transactions(lnk, format = 'single', cols = c(1, 2), sep = ';'))

transDat2 <- suppressAll(read.transactions(lnk, format = 'basket', sep = ';'))

```

```{r write-file, echo = FALSE}
#'@ txt <- suppressWarnings(readBin(lnk, what = 'character')) #only read first 1000 words but all more than 220000 words.
txt <- lnk %>% read_html %>% html_text
txt %<>% str_replace_all('\n', ';') %>% str_split(';') %>% .[[1]] %>% na.omit

uniqueItem <- sort(unique(txt))

# write(transDat, file = './4 Pattern Discovery in Data Mining/data/single.txt', sep = ';')

# write(transDat2, file = './4 Pattern Discovery in Data Mining/data/basket.txt', sep = ';')
```

## 1.2 Output

  You need to implement the Apriori algorithm and use it to mine category sets that are frequent in the input data. When implementing the Apriori algorithm, you may use any programming language you like. We only need your result pattern file, not your source code file.

  After implementing the Apriori algorithm, please set the relative minimum support to 0.01 and run it on the 77,185 category lists. In other words, you need to extract all the category sets that have an absolute support no smaller than 771.

### Part 1

  Please output all the length-1 frequent categories with their absolute supports into a text file named "patterns.txt". Every line corresponds to exactly one frequent category and should be in the following format:

`support:category`

  For example, suppose a category (Fast Food) has an absolute support 3000, then the line corresponding to this frequent category set in "patterns.txt" should be:

`3000:Fast Food`

### Part 2

  Please write all the frequent category sets along with their absolute supports into a text file named "patterns.txt". Every line corresponds to exactly one frequent category set and should be in the following format:

`support:category_1,category_2,category_3,...`

  For example, suppose a category set (Fast Food; Restaurants) has an absolute support 2851, then the line corresponding to this frequent category set in "patterns.txt" should be:

`2851:Fast Food;Restaurants`

## 1.3 Important Tips

  Make sure that you format each line correctly in the output file. For instance, use a semicolon instead of another character to separate the categories for each frequent category set.

  In the result pattern file, the order of the categories does not matter. For example, the following two cases will be considered equivalent by the grader:

Case 1:

`2851:Fast Food;Restaurants`

Case 2:

`2851:Restaurants;Fast Food`

# 2. My submission

  - Section [2.1 Frequent Single Item Mining]
  - Section [2.2 Frequent Itemset Mining using Apriori]

**Upload Files and Submit**

  To upload a file, click the part below. Then, submit the files. You can submit as many times as you like. You do not need to upload all parts in order to submit.
  
  - Frequent Single Item Mining (*30 points*)
  - Frequent Itemset Mining using Apriori (*70 points*)

## 2.1 Frequent Single Item Mining

```{r item1a, echo = FALSE, results = 'asis'}
itemFrequencyPlot(transDat, topN = 20, type = 'absolute', col = rainbow(4))
```

*graph 2.1.1a : explore the top 20 items in the dataset.*

```{r item1b, echo = FALSE, results = 'asis'}
itemFrequencyPlot(transDat2, topN = 20, type = 'absolute', col = rainbow(4))
```

*graph 2.1.1b : explore the top 20 items in the dataset.*

```{r item2a}
inspect(transDat[1:10]) # view the observations
length(transDat) # get number of observations
size(transDat[1:10]) # number of items in each observation

## Endless proceed 3 hours due to length of list, here I omit LIST() and only process inspect().
#'@ LIST(transDat) # convert 'transactions' to a list, note the LIST in CAPS
```

```{r item2b}
inspect(transDat2[1:100]) # view the observations
length(transDat2) # get number of observations
size(transDat2[1:100]) # number of items in each observation

## Endless proceed 3 hours due to length of list, here I omit LIST() and only process inspect().
#'@ LIST(transDat) # convert 'transactions' to a list, note the LIST in CAPS
```

```{r item3a}
head(transDat)
```

```{r item3b}
head(transDat2)
```

```{r item4a}
frequentItems <- eclat(transDat, parameter = list(supp = 0.07, maxlen = 15)) # calculates support for frequent items

itemFrequencyPlot(transDat, topN = 10, type = 'absolute', col = rainbow(4)) # plot frequent items
```

*graph 2.1.2a : top 10 items in dataset.*

```{r item4b}
frequentItems <- eclat(transDat2, parameter = list(supp = 0.07, maxlen = 15)) # calculates support for frequent items

itemFrequencyPlot(transDat2, topN = 10, type = 'absolute', col = rainbow(4)) # plot frequent items
```

*graph 2.1.2b : top 10 items in dataset.*

## 2.2 Frequent Itemset Mining using Apriori

```{r apriori-a}
# Get the rules
rules <- apriori(transDat, parameter = list(supp = 0.01, conf = 0.5))
 
# Show the top 5 rules, but only 2 digits
options(digits=2)
inspect(sort(subset(rules[1:5], subset = lift > 6), by = 'confidence'))
```

```{r apriori-b}
# Get the rules
rules <- apriori(transDat2, parameter = list(supp = 0.01, conf = 0.5))
 
# Show the top 5 rules, but only 2 digits
options(digits=2)
inspect(sort(subset(rules[1:5], subset = lift > 6), by = 'confidence'))
```

```{r plot1, echo = FALSE, results = 'asis'}
## All plots unable proceed...

# Interactive Plot
#'@ plot(rules[1:25], method = 'graph', interactive = TRUE, shading = 'confidence') # feel free to expand and move around the objects in this plot

#'@ plot(rules[1:25])

#'@ plot(rules[1:25], method = 'grouped', control = list(k = 20))

#'@ plot(rules[1:25], measure = c('support', 'lift'), shading = 'confidence')

#'@ plot(rules[1:25], method = NULL, measure = 'support', shading = 'lift', interactive = FALSE)
```

```{r gvis-setting, echo = FALSE, results = 'asis'}
## Set options back to original options
options(op)
```

# 3. Conclusion

  I will also conducting a market basket analysis in [Betting Strategy and Model Validation](https://github.com/scibrokes/betting-strategy-and-model-validation) with regards sportsbook betting.


# 4. Appendices

  - Section [4.1 Documenting File Creation ]
  - Section [4.2 Speech and Blooper]
  - Section [4.3 References]

## 4.1 Documenting File Creation 

  It's useful to record some information about how your file was created.

  - File creation date: 2016-09-03
  - File latest updated date: `r Sys.Date()`
  - `r R.version.string`
  - R version (short form): `r getRversion()`
  - [**rmarkdown** package](https://github.com/rstudio/rmarkdown) version: `r packageVersion('rmarkdown')`
  - [**tufte** package](https://github.com/rstudio/tufte) version: `r packageVersion('tufte')`
  - File version: 1.0.0
  - Author Profile: [®γσ, Eng Lian Hu](https://beta.rstudioconnect.com/englianhu/ryo-eng/)
  - GitHub: [Source Code](https://github.com/englianhu/Coursera-Data-Mining/blob/master/4%20Pattern%20Discovery%20in%20Data%20Mining/Programming%20Assignment%20-%20Frequent%20Itemset%20Mining%20Using%20Apriori.Rmd)
  - Additional session information
  
```{r info, echo = FALSE, warning = FALSE, results = 'asis'}
suppressMessages(require('dplyr', quietly = TRUE))
suppressMessages(require('formattable', quietly = TRUE))

lubridate::now()
sys1 <- devtools::session_info()$platform %>% unlist %>% data.frame(Category = names(.), session_info = .)
rownames(sys1) <- NULL
sys1 %>% formattable %>% as.htmlwidget

data.frame(Sys.info()) %>% mutate(Category = rownames(.)) %>% .[2:1] %>% rename(Category = Category, Sys.info =  Sys.info..) %>% formattable %>% as.htmlwidget

rm(sys1)
```

## 4.2 Speech and Blooper

  All `plot()` funtion for `arules` in rmarkdown unable work but run chunk-by-chunk is working fine.

## 4.3 References

1. [A biased comparsion of JSON packages in R](https://rstudio-pubs-static.s3.amazonaws.com/31702_9c22e3d1a0c44968a4a1f9656f1800ab.html)
2. [**Introduction to arules – A computational environment for mining association rules and frequent item sets** *by Michael Hahsler, Bettina Grun, Kurt Hornik, Christian Buchta (2015)*](https://cran.r-project.org/web/packages/arules/vignettes/arules.pdf)
3. [**Association Rules and Market Basket Analysis with R** *by David Smith (2015)*](http://blog.revolutionanalytics.com/2015/04/association-rules-and-market-basket-analysis-with-r.html)
4. [**Market Basket Analysis with R** *by Salem (2014)*](http://www.salemmarafi.com/code/market-basket-analysis-with-r/)
5. [**ASSOCIATION MINING: WHAT PRODUCTS TO RECOMMEND TO YOUR CUSTOMERS BASED ON HISTORIC BUYING PATTERNS?** *by RSTATISTICS.NET*](http://rstatistics.net/association-mining-with-r/)
6. [**RPubs - LastFM Prediction Using Market Basket Analysis** *by Ranjit Mishra (2015)*](https://rpubs.com/ranjitmishra/124373)

